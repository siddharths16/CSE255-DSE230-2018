{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Analysis using XGBoost\n",
    "We are going to use boosted trees. The question is: why don't we use the gradient boosted in Spark?\n",
    "\n",
    "THe reason is that, in our experience, XGBoost running on a single machine is much faster than Spark running on 10 machines. So we use XGBoost and am showing you how to use it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.253263Z",
     "start_time": "2018-06-12T16:53:59.579795Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from lib import XGBHelper as xgbh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The data files were preprocessed on PySpark (10 nodes) cluster. The code for the same can be found [here](Data_Processing_Whales.ipynb). The preprocessed is a numpy array with `4175` rows (for the 10mb file) with following columns (zero-indexed):\n",
    "* Col 0-9: projections on first 10 eigen vectors\n",
    "* Col 10: rmse\n",
    "* Col 11: peak2peak\n",
    "* Col 12: label (`0 if row.species==u'Gervais' else 1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.266149Z",
     "start_time": "2018-06-12T16:54:00.255404Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Use Data/processed_data_150mb.np for a slightly bigger file\n",
    "data  = np.load(\"Data/processed_data_15mb.np\")\n",
    "X = data[:, :-1]\n",
    "y = np.array(data[:, -1], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train - Test - Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The data is shuffled and divided as follow:\n",
    "* Training: 70%\n",
    "* Validation: 15%\n",
    "* Testing: 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.277120Z",
     "start_time": "2018-06-12T16:54:00.268326Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Training and Feature Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Setting Parameters for XG Boost\n",
    "* Maximum Depth of the Tree = 3 _(maximum depth of each decision trees)_\n",
    "* Step size shrinkage used in update to prevents overfitting = 0.3 _(how to weigh trees in subsequent iterations)_\n",
    "* Evaluation Criterion= Maximize Loglikelihood according to the logistic regression _(logitboost)_\n",
    "* Maximum Number of Iterations = 1000 _(total number trees for boosting)_\n",
    "* Early Stop if score on Validation does not improve for 5 iterations\n",
    "\n",
    "[Full description of options](https://xgboost.readthedocs.io/en/latest//parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:24.874794Z",
     "start_time": "2018-06-12T16:54:24.863101Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'eta': 0.3, 'silent': 0, 'objective': 'binary:logistic', 'nthread': 7, 'eval_metric': 'logloss'}\n"
     ]
    }
   ],
   "source": [
    "param={}\n",
    "param['max_depth']= 3   # depth of tree\n",
    "param['eta'] = 0.3      # shrinkage parameter\n",
    "param['silent'] = 0     # not silent\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['nthread'] = 7 # Number of threads used\n",
    "param['eval_metric'] = 'logloss'\n",
    "\n",
    "plst = param.items()\n",
    "print(param)\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: Running XGBoost for 1000 iterations **On the full data** takes about 70-80 minutes to train. Use **verbose_eval=True** to track number of iterations complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:30.871142Z",
     "start_time": "2018-06-12T16:54:27.377199Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.87 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# bst1000 is model with 1000 iterations\n",
    "num_round = 1000\n",
    "# Use early_stopping_rounds=5 to enable early stopping\n",
    "bst1000 = xgb.train(plst, dtrain, num_round, evallist, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize the Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:30.892954Z",
     "start_time": "2018-06-12T16:54:30.887138Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "features_map = {'f0' : 'Eigen Projection 1', 'f1' : 'Eigen Projection 2',\n",
    "                'f2' : 'Eigen Projection 3', 'f3' : 'Eigen Projection 4',\n",
    "                'f4' : 'Eigen Projection 5', 'f5' : 'Eigen Projection 6',\n",
    "                'f6' : 'Eigen Projection 7', 'f7' : 'Eigen Projection 8',\n",
    "                'f8' : 'Eigen Projection 9', 'f9' : 'Eigen Projection 10',\n",
    "                'f10' : 'RMSE', 'f11' : 'Peak2Peak'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:30.920779Z",
     "start_time": "2018-06-12T16:54:30.908836Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Iterations\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b887a1fa4a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"100 Iterations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgbh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bst' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"100 Iterations\")\n",
    "xgbh.visualize_features(bst, features_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.385412Z",
     "start_time": "2018-06-12T16:54:00.862Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"1000 Iterations\")\n",
    "xgbh.visualize_features(bst1000, features_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Margin Plots on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.386199Z",
     "start_time": "2018-06-12T16:54:00.864Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred_1000 = bst1000.predict(dtest, ntree_limit=bst1000.best_ntree_limit, output_margin=True)\n",
    "y_test = dtest.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.387004Z",
     "start_time": "2018-06-12T16:54:00.866Z"
    },
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# #Uncomment this part if you want to load directly from the pickle file instead of running XGBoost for 1000 iterations on the entire data.\n",
    "# #Processed pickle file (xgboost_output_full_data.pk) has been provided. \n",
    "# import pickle\n",
    "\n",
    "# #Processed output after running them on a model\n",
    "# p = pickle.load(open('Data/xgboost_output_full_data.pk', 'rb'))\n",
    "\n",
    "# y_test = np.array(p['y_test'], dtype = int)\n",
    "# y_pred_100 = p['y_pred_100']\n",
    "# y_pred_1000 = p['y_pred_1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.387795Z",
     "start_time": "2018-06-12T16:54:00.868Z"
    },
    "hide_input": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "for _train_size in [0.03,0.1,0.8]:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=_train_size,test_size=1-_train_size)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, y_val)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        legends=[]\n",
    "        # Use early_stopping_rounds=5 to enable early stopping\n",
    "        for num_round in [10,100]:\n",
    "            bst = xgb.train(plst, dtrain, num_round, evallist, verbose_eval=False)\n",
    "            y_pred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit, output_margin=True)\n",
    "            thresholds = sorted(np.unique(np.round(y_pred, 2)))\n",
    "            error_cuv, error_ger = xgbh.get_error_values(y_pred, y_test, thresholds)\n",
    "            legends += ['Cuviers %d'%num_round, 'Gervais %d'%num_round]\n",
    "            _style=['y','g'] if num_round==100 else ['b', 'r']\n",
    "            xgbh.get_margin_plot(error_cuv, error_ger, thresholds, legends = legends, style=_style)\n",
    "        \n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='gray')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "        thr = thresholds_100/(np.max(thresholds_100) - np.min(thresholds_100))\n",
    "    plt.title('data_size=%4.3f'%(X_train.shape[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Per example variation analysis\n",
    "The CDFs provide information on the variation of the aggregate. If we want to estimate of the confidence on a single examples we need to compute the variance **per example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.388558Z",
     "start_time": "2018-06-12T16:54:00.870Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "data  = np.load(\"Data/processed_data_15mb.np\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.389516Z",
     "start_time": "2018-06-12T16:54:00.872Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "#plt.plot(fpr, tpr)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test, y_pred_1000)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title(\"ROC Curve after 100 iterations\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.390521Z",
     "start_time": "2018-06-12T16:54:00.874Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_error_ranges(error_cuv_samp, error_ger_samp, thresholds_samp, num_chunks=20):\n",
    "    error_cuv_bin = np.array(np.array(error_cuv_samp) * num_chunks, dtype=int)\n",
    "    error_cuv_bin[error_cuv_bin == num_chunks] = num_chunks - 1\n",
    "    error_ger_bin = np.array(np.array(error_ger_samp) * num_chunks, dtype=int)\n",
    "    error_ger_bin[error_ger_bin == num_chunks] = num_chunks - 1\n",
    "    \n",
    "    min_cuv = np.zeros(num_chunks, dtype=float)\n",
    "    max_cuv = np.zeros(num_chunks, dtype=float)\n",
    "    min_ger = np.zeros(num_chunks, dtype=float)\n",
    "    max_ger = np.zeros(num_chunks, dtype=float)\n",
    "    \n",
    "    normalizing_factor = (max(thresholds_samp) - min(thresholds_samp))\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        min_cuv[i] = thresholds_samp[np.min(np.where(error_cuv_bin == i))]/normalizing_factor\n",
    "        max_cuv[i] = thresholds_samp[np.max(np.where(error_cuv_bin == i))]/normalizing_factor\n",
    "        min_ger[i] = thresholds_samp[np.max(np.where(error_ger_bin == i))]/normalizing_factor\n",
    "        max_ger[i] = thresholds_samp[np.min(np.where(error_ger_bin == i))]/normalizing_factor\n",
    "            \n",
    "    return min_cuv, max_cuv, min_ger, max_ger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.391723Z",
     "start_time": "2018-06-12T16:54:00.877Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def generate_samples(data, size=500, num_chunks=20):\n",
    "    for i in range(200):\n",
    "        if i == 0:\n",
    "            min_cuv = np.zeros(num_chunks, dtype=float)\n",
    "            max_cuv = np.zeros(num_chunks, dtype=float)\n",
    "            min_ger = np.zeros(num_chunks, dtype=float)\n",
    "            max_ger = np.zeros(num_chunks, dtype=float)\n",
    "        \n",
    "        #Sampling Random indices for selection\n",
    "        samp_indices = np.random.randint(len(data), size=size)\n",
    "        \n",
    "        #Test data and labels\n",
    "        X_samp = data[samp_indices, :-1]\n",
    "        y_samp = np.array(data[samp_indices, -1], dtype=int)\n",
    "        \n",
    "        #Test predictions\n",
    "        dsamp = xgb.DMatrix(X_samp, label=y_samp)    \n",
    "        y_samp_pred = bst.predict(dsamp, ntree_limit=bst.best_ntree_limit, output_margin=True)\n",
    "\n",
    "        thresholds_samp = sorted(np.unique(np.round(y_samp_pred, 2)))\n",
    "        error_cuv_samp, error_ger_samp = xgbh.get_error_values(y_samp_pred, y_samp, thresholds_samp)\n",
    "        \n",
    "        min_cuv_samp, max_cuv_samp, min_ger_samp, max_ger_samp = get_error_ranges(error_cuv_samp, error_ger_samp, thresholds_samp)\n",
    "        \n",
    "        if i == 0:\n",
    "            min_cuv = min_cuv_samp\n",
    "            max_cuv = max_cuv_samp\n",
    "            min_ger = min_ger_samp\n",
    "            max_ger = max_ger_samp\n",
    "        else:\n",
    "            min_cuv[min_cuv > min_cuv_samp] = min_cuv_samp[min_cuv > min_cuv_samp]\n",
    "            max_cuv[max_cuv < max_cuv_samp] = max_cuv_samp[max_cuv < max_cuv_samp]\n",
    "            min_ger[min_ger > min_ger_samp] = min_ger_samp[min_ger > min_ger_samp]\n",
    "            max_ger[max_ger < max_ger_samp] = max_ger_samp[max_ger < max_ger_samp]         \n",
    "    \n",
    "    for i in range(20):\n",
    "        plt.plot([min_cuv[i], max_cuv[i]], [i/20.0, i/20.0], 'b')\n",
    "        plt.plot([min_ger[i], max_ger[i]], [i/20.0, i/20.0], 'r')\n",
    "    #print(min_cuv, max_cuv, min_ger, max_ger)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T16:54:00.392938Z",
     "start_time": "2018-06-12T16:54:00.879Z"
    },
    "hide_input": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "#legends = ['Cuviers', 'Gervais']\n",
    "\n",
    "#Best thresholds from the ROC Analysis\n",
    "thr_lower_index = np.min(np.where((tpr > 0.95)))\n",
    "thr_upper_index = np.max(np.where((tpr  < 0.6)))\n",
    "thr_lower, thr_upper = thresholds[thr_lower_index], thresholds[thr_upper_index]\n",
    "thr_lower_norm = thr_lower/(np.max(thresholds) - np.min(thresholds))\n",
    "thr_upper_norm = thr_upper/(np.max(thresholds) - np.min(thresholds))\n",
    "print(\"Thresholds (lower, upper):\", thr_lower_norm, thr_upper_norm)\n",
    "\n",
    "\n",
    "generate_samples(data, num_chunks=20)\n",
    "\n",
    "#xgbh.get_margin_plot(error_cuv_100, error_ger_100, thresholds_100, legends = legends, style=['y', 'g'])\n",
    "plt.plot([thr_lower_norm, thr_lower_norm], [0, 1], 'm:')\n",
    "plt.plot([thr_upper_norm, thr_upper_norm], [0, 1], 'm:')\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='gray')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "plt.xlabel('Margin Score')\n",
    "plt.ylabel('Error %')\n",
    "legends = ['Cuviers_100', 'Gervais_100']\n",
    "plt.legend(legends)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
